## ⚡️ LLM-Inference-Techniques ⚡️

Implementations and extrapolations of frontier inference papers. My goal with this project is to make implementations of these frontier techniques available to everyone who wants to experiment and build upon them.

Currently Includes:
1) [MCTSelf-refine](https://arxiv.org/pdf/2406.07394)
2) [rStar-Math](https://arxiv.org/abs/2501.04519) (human-like action based MCTS with mutual consistency)
3) rStar-Coder (extrapolation of rStar-Math for programming problems)
4) Wizard (action based tree search for maximizing breadth of solutions and common errors)

## ✨ Contributions ✨

To refine old or add new techniques (please do contribute I am very interested in learning more from implementations or comments)

Feel free to change the repo structure if anything feels unintuitive, or other macro-level improvements. 

Steps:
- Fork the repo and create a feature branch from `main`.
- Keep edits focused; add tests or notebook cells if relevant. For new techniques just send the whole notebook/file.
- Run notebooks you changed and clear noisy outputs before commit.
- Use conventional commit messages where practical (feat, fix, docs, chore).
- Open a PR with a brief description, screenshots (if visuals), steps to reproduce, and the paper you are referencing (if relevant).

- You could also open an issue and let someone else pick it up.
